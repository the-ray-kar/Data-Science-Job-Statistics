{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import List\n",
    "\n",
    "class TechStack(BaseModel):\n",
    "    GPU_Frameworks: List[str] = Field(..., alias=\"GPU Frameworks\")\n",
    "    Programming_Languages: List[str] = Field(..., alias=\"Programming Languages\")\n",
    "    Generative_AI_Frameworks: List[str] = Field(..., alias=\"Generative AI Frameworks\")\n",
    "    Databases: List[str] = Field(..., alias=\"Databases\")\n",
    "    Orchestration_Deployment: List[str] = Field(..., alias=\"Orchestration & Deployment\")\n",
    "    APIs_Web_Frameworks: List[str] = Field(..., alias=\"APIs & Web Frameworks\")\n",
    "    Big_Data_Technologies: List[str] = Field(..., alias=\"Big Data Technologies\")\n",
    "    Cloud_Platforms_Services: List[str] = Field(..., alias=\"Cloud Platforms & Services\")\n",
    "    Machine_Learning_Deep_Learning_Libraries: List[str] = Field(..., alias=\"Machine Learning & Deep Learning Libraries\")\n",
    "    Data_Visualization_Tools: List[str] = Field(..., alias=\"Data Visualization Tools\")\n",
    "    CI_CD_MLOps: List[str] = Field(..., alias=\"CI/CD & MLOps\")\n",
    "    Model_Formats_Optimization: List[str] = Field(..., alias=\"Model Formats & Optimization\")\n",
    "    Qualifications: List[str] = Field(..., alias=\"Qualifications\")\n",
    "    Machine_Learning_AI_Techniques: List[str] = Field(..., alias=\"Machine Learning & AI Techniques\")\n",
    "    Machine_Learning_AI_Models: List[str] = Field(..., alias=\"Machine Learning & AI Models\")\n",
    "    Tasks_Responsibilities: List[str] = Field(..., alias=\"Tasks & Responsibilities\")\n",
    "    Soft_Skills: List[str] = Field(..., alias=\"Soft Skills\")\n",
    "    Miscellaneous: List[str] = Field(..., alias=\"Miscellaneous\")\n",
    "\n",
    "    class Config:\n",
    "        populate_by_name = True  # Allows using both alias and field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompt_template\",\"r\") as f:\n",
    "    prompt_template= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "if os.path.exists(\"text_list.pkl\"):\n",
    "    with open(\"text_list.pkl\", \"rb\") as f:\n",
    "            all_descriptions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Job Descriptions 167\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Job Descriptions\",len(all_descriptions))\n",
    "raw_description = all_descriptions[100]\n",
    "job_description = \"\\n'''\" + raw_description+\"\\n'''\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'''Key Responsibilities:\n",
      "\n",
      "    ML backend and Orchestration:\n",
      "        Hands on development of ML Systems backend infrastructure, messaging and integration with interfacing systems\n",
      "        Design, build, and maintain APIs, Microservices, and systems to serve data science models.\n",
      "        Ensure ML Infrastructure systems are scalable, reliable, and secure\n",
      "    Database Management:\n",
      "        Work with SQLAlchemy to define, maintain, and query the database schema for an application.\n",
      "        Work with raw SQL to run advanced queries for things like alerting and reporting.\n",
      "    ML Ops Implementation:\n",
      "        Develop and maintain CI/CD pipelines for data science models and services\n",
      "        Automate and track data science workflows with tools like MLflow\n",
      "    Infrastructure:\n",
      "        Manage and optimize Kubernetes cluster via Openshift.\n",
      "        Implement and manage various infrastructure components such as PostgreSQL, Kafka, S3.\n",
      "        Knowledge of running workloads in AWS or GCP will be plus.\n",
      "    Collaboration:\n",
      "        Work with data scientists to understand model requirements and ensure successful deployment into production systems\n",
      "        Collaborate with DevOps and infrastructure teams to improve scalability and reliability\n",
      "    Performance & Optimization:\n",
      "        Optimize backend services and data science model inference for latency and throughput\n",
      "        Troubleshoot issues in production environments, ensuring high availability of services\n",
      "    Engineering Excellence & Best Practices:\n",
      "\n",
      "        Drive the adoption of modern engineering ways of working, including Agile, DevOps, and CI/CD.\n",
      "        Advocate for automated testing, infrastructure as code, and continuous monitoring to enhance software reliability.\n",
      "        Apply Behavior-Driven Development (BDD), Test-Driven Development (TDD), and unit testing to ensure code quality and functionality.\n",
      "        Conduct thorough code reviews, ensuring adherence to best practices in readability, performance, and security.\n",
      "        Implement and enforce secure coding practices, performing vulnerability assessments and ensuring compliance with security standards.\n",
      "        Collaborate effectively in agile environments, embracing DevOps principles and fostering a culture of continuous delivery and improvement.\n",
      "\n",
      "    Skills & Qualifications:\n",
      "\n",
      "        Proficiency in Python\n",
      "        Hands on experience working with a Python web framework such as FastAPI, Flask, Django, etc\n",
      "        Peripheral knowledge in Machine Learning and Data Science\n",
      "        Working knowledge in MLOps principals such as experiment tracking, model serving, model orchestration, etc.\n",
      "        Hands on experience with designing DB driven applications and using an ORM such as SQLAlchemy.\n",
      "        Hands on experience with deploying and maintaining production applications\n",
      "        Hands on experience with managing and debugging the necessary infrastructure to support a full stack application\n",
      "        Hands on experience with Kubernetes\n",
      "        Hands on experience working with stream processing tools like Kafka or Apache Spark\n",
      "        Bachelor’s degree or equivalent experience in Computer Science or a related field.\n",
      "\n",
      "    Ideal skills:\n",
      "\n",
      "        Hands on experience working with a Python orchestrator (Dagster, Airflow, Prefect, etc)\n",
      "        Hands on experience working with various MLOps tools such as MLFlow, Kedro, etc\n",
      "        Hands on experience working with LLMs and related technologies such as Vector DBs, Agents, etc.\n",
      "\n",
      "\n",
      "'''\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template+job_description\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"GPU Frameworks\": [],\n",
      "  \"Programming Languages\": [\n",
      "    \"Python\", \"SQL\"\n",
      "    ],\n",
      "  \"Generative AI Frameworks\": [],\n",
      "  \"Databases\": [\n",
      "    \"PostgreSQL\", \"MongoDB\"\n",
      "    ],\n",
      "  \"Orchestration & Deployment\": [\n",
      "    \"Kubernetes\", \"MLflow\", \"Airflow\"\n",
      "  ],\n",
      "  \"APIs & Web Frameworks\": [\n",
      "    \"REST API\", \"FastAPI\", \"Flask\", \"GraphQL\"\n",
      "  ],\n",
      "  \"Big Data Technologies\": [\n",
      "    \"Apache Spark\", \"Kafka\"\n",
      "  ],\n",
      "  \"Cloud Platforms & Services\": [\n",
      "    \"AWS\", \"Google Cloud Platform (GCP)\"\n",
      "  ],\n",
      "  \"Machine Learning & Deep Learning Libraries\": [\n",
      "    \"SQLAlchemy\"\n",
      "  ],\n",
      "  \"Data Visualization Tools\": [],\n",
      "  \"CI/CD & MLOps\": [\n",
      "    \"Airflow\", \"Jenkins\", \"Kubeflow\"\n",
      "  ],\n",
      "  \"Model Formats & Optimization\": [],\n",
      "  \"Qualifications\": [\n",
      "    \"BS\", \"BSc\"\n",
      "  ],\n",
      "  \"Machine Learning & AI Techniques\": [\n",
      "    \"Machine Learning\", \"Natural Language Processing (NLP)\", \"Generative AI\"\n",
      "  ],\n",
      "  \"Machine Learning & AI Models\": [\n",
      "    \"Transformers\", \"LLaMA\"\n",
      "  ],\n",
      "  \"Tasks & Responsibilities\": [\n",
      "    \"Build & Train Machine Learning Models\", \"Deploy Machine Learning Models\", \"Maintain & Monitor Model Performance\"\n",
      "  ],\n",
      "  \"Soft Skills\": [],\n",
      "  \"Miscellaneous\": []\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "job_json = response.text.strip(\"`\").replace(\"json\", \"\", 1).replace(\"\\n\",\"\")\n",
    "job_json = json.loads(job_json)\n",
    "mystack = TechStack.model_validate(job_json)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Knowledge / Experience\n",
      "\n",
      "    Proven working experience in data analysis and ML modeling\n",
      "    Deep unde\n",
      "1 \n",
      "\n",
      "    Collaborate with multi-functional teams to find opportunities to apply data-driven insights an\n",
      "2 \n",
      "\n",
      "Must have:\n",
      "\n",
      "    MS/PhD in a relevant technical field from premium institutes such as or equivalent\n",
      "3 Primary Skills – Python, AI, ML (Machine Learning) Gen AI – Generative AI + RAG, NLP, LLM, Deep Lear\n",
      "4 \n",
      "About the job\n",
      "\n",
      "Role- Generative AI Engineer (GEN AI)\n",
      "\n",
      "Experience- 4 to 8yrs\n",
      "\n",
      "Location- Pune Hyderab\n",
      "5  We are looking for pseudo–Research Profiles having\n",
      "\n",
      "    8+ years of experience on Python.\n",
      "    Profi\n",
      "6 ey Responsibilities:\n",
      "\n",
      "    Design and Develop Machine Learning/Deep Learning Models: Design, develop,\n",
      "7 Basic Requirements:\n",
      "\n",
      "    On-site working at the ML physical office, 5-days per week required\n",
      "    Adv\n",
      "8 \n",
      "The AI Engineer will focus on developing, deploying, and maintaining solutions that use AI to drive\n",
      "9 In this role, you will be responsible for designing, developing, and deploying machine learning mode\n",
      "10 Key Responsibilities:\n",
      "\n",
      "    Develop end-to-end AI/ML solutions, from data collection and preprocessin\n",
      "11 What We Look For\n",
      "\n",
      "    Bachelor's or master’s degree in computer science, Statistics, Mathematics, or\n",
      "12 e are seeking a skilled Data Scientist with expertise in Generative AI and Machine Learning to join \n",
      "13 \n",
      "\n",
      "    Designing and training machine learning models.\n",
      "    Evaluating model performance and iterating\n",
      "14 Key Duties And Responsibilities\n",
      "\n",
      "     Research and prototype vision tranaformer models with ideas fr\n",
      "15 ob Description\n",
      "\n",
      "Who You’ll Work With\n",
      "\n",
      "Arista is excited to scale the WiFi Team in the Pune Developme\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "16 oin us in:\n",
      "\n",
      "    Bringing large volumes of data from wind, solar, storage sites to cloud\n",
      "    Building\n",
      "17 Who You Are\n",
      "\n",
      "    5+ years of full-time work experience as a data scientist (prefarbly within related\n",
      "18 \n",
      "\n",
      "    4-5 years of relevant experience\n",
      "    Training/Certification in Data Science/Machine Learning i\n",
      "19 Job Summary:\n",
      "\n",
      "We are looking for an experienced Data Scientist with 5-6 years of hands-on\n",
      "\n",
      "experienc\n",
      "20 What you’ll do:\n",
      "\n",
      "    Design, build, and maintain machine learning and statistical models to optimize\n",
      "21 Job Description\n",
      "\n",
      "We’re looking for a passionate and talented Senior Data Scientist to join our growi\n",
      "22 We are looking for a passionate and talented Senior Data Scientist to join our growing team. In this\n",
      "23 Responsibilities\n",
      "\n",
      "    Software Development: Design, develop, and maintain data processing applicatio\n",
      "24 Responsibilities:\n",
      "- Develop next-gen algorithms to understand visual content and textual content and\n",
      "25 Looking for a Data Science professional with expertise in PySpark/Databricks and experience working \n",
      "26 Responsibilities: - \n",
      "\n",
      "    Working with business stakeholders to define and ideate data science-based\n",
      "27 Experience- 5 to 8 Years\n",
      "\n",
      "Job Location- Bangalore\n",
      "\n",
      "Notice Period- Immediate to 30 Days\n",
      "\n",
      "\n",
      "Primary ski\n",
      "28 What you will do (Responsibilities):\n",
      "\n",
      "\n",
      "    Perform high-level work both independently and collaborat\n",
      "29 What you will do (Responsibilities):\n",
      "\n",
      "\n",
      "    Perform high-level work both independently and collaborat\n",
      "30 \n",
      "\n",
      "    Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equ\n",
      "31 \n",
      "\n",
      "    Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equ\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "32 \n",
      "\n",
      "    4-7 years of relevant experience\n",
      "    Training/Certification in Data Science/Machine Learning i\n",
      "33 As Data Scientist you will have following main accountabilities:\n",
      "\n",
      "    You own together with your tea\n",
      "34  \n",
      "\n",
      " What will you be responsible for\n",
      "\n",
      "As a Lead Data Scientist, you will be responsible to develop e\n",
      "35 \n",
      "\n",
      "    4-6 years of work experience with a bachelor’s degree or 3+ years of work experience with an A\n",
      "36 Responsibilities\n",
      "\n",
      "     Design, develop, and deploy AI models and systems. \n",
      "     Collaborate with cro\n",
      "37 AI/ML Engineer Responsibilities\n",
      "\n",
      "    Designing machine learning systems and self-running artificial \n",
      "38 \n",
      "\n",
      "Mandatory Skills : MLOPS, Data Engineering,CI/CD,\n",
      "\n",
      "Preferred Skills : API integration\n",
      "\n",
      "Job Descrip\n",
      "39 Key Responsibilities:\n",
      "\n",
      "    Model Development: Design, build, and implement scalable machine learning\n",
      "40 he Data Scientist should be capable to provide continuous data exploration and insights to help the \n",
      "41 Must-Have\n",
      "\n",
      "\n",
      " Experience in Python, Pandas, Numpy \n",
      "\n",
      "Experience in NLP Techniques \n",
      "\n",
      "Experience in RASA\n",
      "42 Responsibilities:\n",
      "\n",
      "    At-least 6+ years of proven experience as a data scientist\n",
      "    Experience in \n",
      "43 What you’ll do:\n",
      "\n",
      "    As part of the data team, contribute to solving business problems by framing th\n",
      "44 Data Science:\n",
      "\n",
      "    Assembling large, complex sets of data Identifying, implementing internal process\n",
      "45 You will work with researchers, data scientist, developers and architects to develop, deploy, and ma\n",
      "46 Experience : 2-6 Years\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Job Description\n",
      "\n",
      "     Traditional AI Development:\n",
      "     Im\n",
      "47  Job Responsibilities(JR) : 6 – 8 Areas \n",
      "\n",
      " Actionable (4-6)\n",
      "\n",
      " · Scorecard Building and Modelling\n",
      "\n",
      " \n",
      "\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "48  Job Responsibilities(JR) : 6 – 8 Areas \n",
      "\n",
      " Actionable (4-6)\n",
      "\n",
      " · Scorecard Building and Modelling\n",
      "\n",
      " \n",
      "\n",
      "49 We are looking for a skilled and detail-oriented Data Scientist with 3+ years of experience to join\n",
      "\n",
      "50 About Mettler Toledo\n",
      "METTLER TOLEDO is a global leader in precision instruments and services. We are\n",
      "51 \n",
      "\n",
      "Role: Gen AI Engineer \n",
      "\n",
      "Location: Pune & Bangalore \n",
      "\n",
      "Experience: 3-5 Yrs \n",
      "\n",
      "\n",
      "Job Specifications: \n",
      "\n",
      "\n",
      "52 \n",
      "About the job\n",
      "\n",
      "Experience:- 6 to 15 years\n",
      "\n",
      "Company:- ACL Digital\n",
      "\n",
      "Notice Period:- Immediate joiner\n",
      "\n",
      "53 ob Description\n",
      "\n",
      " \n",
      "\n",
      "We are immediately hiring a results-oriented Senior Machine Learning Engineer to \n",
      "54 ob Type: Full-time\n",
      "\n",
      "Experience : 2-6 Years\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Job Description\n",
      "\n",
      "     Traditional AI \n",
      "55 Senior Data Scientist:\n",
      "\n",
      "The Data Analytics as a Service (da3s) team within Innovation & Engineering \n",
      "56 \n",
      "\n",
      "Location : Mumbai \n",
      "\n",
      "Experience – 3 – 5 yrs \n",
      "\n",
      "Job brief : \n",
      "\n",
      "We seek a highly skilled AI/ML Engineer\n",
      "57 Strong professional background in NLP Familiarity with concepts such as Attention Mechanism, Self-At\n",
      "58 \n",
      "Responsibilities\n",
      "\n",
      "\n",
      "    Design, develop, and implement novel data science models and machine learnin\n",
      "59 What are we looking for? Extensive experience in leading Data Science and Advanced Analytics deliver\n",
      "60 esponsibilities:\n",
      "\n",
      "    Closely collaborate with business stakeholders including portfolio management,\n",
      "61 Qualification\n",
      "\n",
      "B.E / B.Tech / MCA / M.Sc. / M. Tech\n",
      "\n",
      "Experience\n",
      "\n",
      "2-6 years\n",
      "\n",
      "Keywords of relevance\n",
      "\n",
      "D\n",
      "62 Experience\n",
      "\n",
      "    3 to 6 years \n",
      "\n",
      "\n",
      "Qualifications\n",
      "\n",
      "    Data normalization, pre-processing and cleaning \n",
      "63 Qualification\n",
      "\n",
      "B.E / B.Tech / MCA / M.Sc. / M. Tech\n",
      "\n",
      "Experience\n",
      "\n",
      "2-6 years\n",
      "\n",
      "Keywords of relevance\n",
      "\n",
      "D\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "64 Qualification\n",
      "\n",
      "B.E / B.Tech / MCA / M.Sc. / M. Tech\n",
      "\n",
      "Experience\n",
      "\n",
      "2-6 years\n",
      "\n",
      "Keywords of relevance\n",
      "\n",
      "D\n",
      "65 • Experience with LLM/Gen AI, including Prompt Engineering, RAG (Retrieval-Augmented Generation), an\n",
      "66 Minimum qualifications:\n",
      "\n",
      "    Bachelor's degree or equivalent practical experience.\n",
      "    2 years of ex\n",
      "67 Responsibilities\n",
      "\n",
      "    Develop scalable and efficient systems for serving AI/ML models, ensuring that\n",
      "68 verview: \n",
      "\n",
      "The Associate Data Scientist supports the development and implementation of data models, \n",
      "69 \n",
      "\n",
      "    Bachelor's or master’s degree in computer science, Statistics, Mathematics, or related field.\n",
      "\n",
      "70 Open for Mumbai/ Pune or Bangalore.\n",
      "\n",
      "Your Key Responsibilities\n",
      "\n",
      "Desing and develop python and AI ML \n",
      "71 Right now, we are looking for Senior Data Scientist to join our team at Globant!\n",
      "\n",
      "Location: Pune/ Hy\n",
      "72 Education/Work Experience:Degree or advanced degree in data science, mathematics, statistics, comput\n",
      "73 Spiro is more than just an electric two-wheelers manufacturing company in Togo, Benin & Rwanda. Spir\n",
      "74 What will you do?\n",
      "\n",
      "    Collaborate with a small, agile team to research and implement effective NLP \n",
      "75 ualifications\n",
      "\n",
      "# Bachelors Degree with relevant experience; Masters degree\n",
      "\n",
      "# Exposure to real-world\n",
      "76 Responsibilities:\n",
      "\n",
      "    Innovate: Design and create datasets and machine learning models that are dri\n",
      "77 Job Location: EON IT Park, Kharadi, Pune (Hybrid)\n",
      "\n",
      "Role: Sr. Manager - Data Scientist\n",
      "\n",
      "Skills: AI/ML\n",
      "78 Key Responsibilities:\n",
      "\n",
      "    Model Development & Deployment: Build, deploy, and maintain machine learn\n",
      "79 What you will do:\n",
      "\n",
      "As a Senior Data Scientists for Walmart Global Tech, you’ll have the opportunity \n",
      "Waiting for 10 seconds API to reset\n",
      "80 Job Description\n",
      "\n",
      "Following our Business Code of Conduct and always acting with integrity and due dil\n",
      "Waiting for 10 seconds API to reset\n",
      "81 We are immediately hiring a results-oriented Senior Machine Learning Engineer to join our growing te\n",
      "82 What you will do ?\n",
      "\n",
      "    Be one of the Individual Contributor and a part of our Data Science practice\n",
      "83 Roles & Responsibilities:\n",
      "\n",
      "\n",
      "     Solve business problems by applying data science and machine learni\n",
      "84 The Role\n",
      "\n",
      "To be successful in this role, the Data Scientist should have a deep knowledge of machine \n",
      "85 Key Responsibilities\n",
      "\n",
      "• Develop RL-based models for industrial robotics, autonomous systems, and sma\n",
      "86 Senior Data Scientist, Pune\n",
      "\n",
      "About This Job\n",
      "\n",
      "NielsenIQ Advanced Analytics team develops and promotes\n",
      "87 \n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "    Design, develop, and deploy machine learning models and algorithms to solve\n",
      "88 Responsibilities:\n",
      "\n",
      "Own multiple projects/areas of research. Work with Data Architects to leverage ex\n",
      "89 \n",
      "Senior Machine Learning Engineer-3\n",
      "\n",
      "Data Scientist – Data and Analytics\n",
      "\n",
      "Career Level 7\n",
      "\n",
      "Who is Mas\n",
      "90 \n",
      "\n",
      "Qualifications\n",
      "\n",
      "    Musts:\n",
      "    MS/PhD in a relevant technical field with an excellent GPA\n",
      "    5 ye\n",
      "91 The business need is understood and formalized in a descriptive datasheet or specifications\n",
      " The met\n",
      "92 In this Role, Your Responsibilities Will Be:\n",
      "\n",
      "    Design, build, and deploy machine learning models \n",
      "93 In this Role, Your Responsibilities Will Be:\n",
      "\n",
      "    Analyze large, sophisticated data sets using stati\n",
      "94 Job Responsibilities\n",
      "\n",
      "    Understand business goals and develop models with measurable success metri\n",
      "95 \n",
      "\n",
      "    Insight Identification: Collaborate with the AI Delivery Owner and key business stakeholders t\n",
      "96 \n",
      "\n",
      "    Undertaking data collection, preprocessing and analysis\n",
      "    Building models to address busines\n",
      "97 Job Responsibility\n",
      "\n",
      "    To design & develop the ADAS (Advanced Driver Assistance Systems) and it's s\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "98 Your Key Responsibilities\n",
      "\n",
      "    Model Deployment: Collaborate with data scientists to deploy machine \n",
      "99 Key job responsibilities\n",
      "\n",
      "This Applied Scientist will lead the science solution design, run experime\n",
      "100 Key Responsibilities:\n",
      "\n",
      "    ML backend and Orchestration:\n",
      "        Hands on development of ML Systems \n",
      "101 Responsibilities:\n",
      "\n",
      "    Develop and maintain LLM-powered applications using Python/JavaScript on Azur\n",
      "102 Your Experience And Qualifications\n",
      "\n",
      "    Bachelor’s degree (B.E. or B.Tech.)\n",
      "    4+ years of experien\n",
      "103 \n",
      "\n",
      "    You hold a Master’s / Graduation in Computer Science, Machine Learning, Artificial Intelligenc\n",
      "104 Your Impact\n",
      "\n",
      "    Research, design, and implement state-of-the-art generative AI model based solution\n",
      "105 Key Responsibilities:\n",
      "\n",
      "     Data Analysis and Insights:\n",
      "     Analyze data from IT-OT integrated syst\n",
      "106 \n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "    Overall 4+ years of experience, out of which in 3+ in AI, ML and Gen AI and\n",
      "107 Key job responsibilities\n",
      "\n",
      "     Serve as a technical expert and leader in building new and enhancing \n",
      "108 Key Responsibilities\n",
      "\n",
      "    Selects analytical techniques and model methods best to solve business pro\n",
      "109 Process Manager Role And Responsibilities\n",
      "\n",
      "     Understand business problem and requirements by buil\n",
      "110 \n",
      "     You understand the foundations of statistics and machine learning and can work in high perform\n",
      "111 Key Responsibilities\n",
      "\n",
      "Develop, evaluate, and deploy models using conventional ML and newer LLM techn\n",
      "112 Essential Responsibilities:\n",
      "\n",
      "The Data Scientist will be responsible to work on data science projects\n",
      "113 Amazon is looking for a passionate, talented, and inventive Scientist with a strong machine learning\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "114 \n",
      "Key job responsibilities\n",
      "\n",
      "     Serve as a technical expert and leader in building new and enhancing\n",
      "Waiting for 10 seconds API to reset\n",
      "115 Your Role And Responsibilities\n",
      "\n",
      "    Work with broader team to build, analyze and improve the AI solu\n",
      "116 The Sr Data Scientist will develop and implement Artificial Intelligence based solutions across vari\n",
      "117 Responsibilities\n",
      "\n",
      "    Innovate and implement cutting-edge Generative AI solutions for novel use case\n",
      "118 ey Responsibilities\n",
      "\n",
      "    Collaborate with a team to innovate and continuously improve dynamic pricin\n",
      "119 You will:\n",
      "\n",
      "    Define requirements for analysis in a given business area and perform detailed analys\n",
      "120 ob Description\n",
      "\n",
      "In Ecosystem & Operational Risk group, Payment Fraud Disruption team is responsible \n",
      "121 Key Responsibilities\n",
      "\n",
      "Experiment Design Analysis: Design, execute, and interpret controlled experime\n",
      "122 XPO India Shared Services\n",
      "\n",
      "What you’ll do on a typical day:\n",
      "\n",
      "    Conceive and develop end-to-end sol\n",
      "123 Company Overview\n",
      "\n",
      "Working at GE Aerospace means you are bringing your unique perspective, innovative\n",
      "124 As a Senior Data and Applied Scientist, you will work with Pattern's Data Science team to curate and\n",
      "125 Roles And Responsibilities\n",
      "\n",
      "Design, Develop, and Deploy: Create and implement advanced machine learn\n",
      "126 \n",
      "In this role, you will have the opportunity to provide technical and business process/data advice t\n",
      "127 Associate Manager Data Science\n",
      "\n",
      "Primary Responsibilities\n",
      "\n",
      "    Support product design and ensure cons\n",
      "128 In this role, you will build and develop ML models to address content understanding problems in Ads.\n",
      "129 Your role\n",
      "Are you interested in pursuing your career in Asset Management? Does working in a data dri\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "130 Job Title: Senior Data Scientist/ Data Scientist\n",
      "\n",
      "Job Location: Bangalore, Pune, Mumbai, Gurgaon, Ch\n",
      "131 Responsibilities\n",
      "\n",
      "    Build, optimize, and deploy scalable data models and machine learning pipeline\n",
      "132 Your Role And Responsibilities\n",
      "\n",
      "As an Associate Data Scientist at IBM, you will work to solve busine\n",
      "133 \n",
      "Marketing & Branding Analytics uses quantitative methods such as business simulations, data mining,\n",
      "134 As an Associate level Data Scientist at IBM, you will work to solve business problems using leading \n",
      "135 Responsibilities:\n",
      "\n",
      "    Incumbents work with large and complex data sets (both internal and external \n",
      "136 Role Description:\n",
      "\n",
      "The Data Scientist is responsible for developing and implementing AI-driven solut\n",
      "137 Roles, Responsibilities & Key Accountabilities:\n",
      "\n",
      "    Develop and deploy machine learning and deep le\n",
      "138 We are seeking a highly skilled and innovative Senior Software Engineer in the TTS (Text-To-Speech) \n",
      "139 We are seeking a highly skilled and innovative Senior Software Engineer in the TTS (Text-To-Speech) \n",
      "140 Senior Data Scientist (Artificial Intelligence Machine Learning)\n",
      "\n",
      "Are you curious, motivated, and fo\n",
      "141 You will be responsible for leading development of innovative AI solutions, working closely with cro\n",
      "142 SciSpace is a product-based startup. AI Assistant for Research using state-of-the-art language model\n",
      "143 About The Role\n",
      "\n",
      "     Familiarizing and adopting work methodology aligning with the existing ACoE org\n",
      "144 About the Role:\n",
      "\n",
      "    Engage with stakeholders, business analysts and project team to understand the \n",
      "145 Minimum Qualifications:\n",
      "\n",
      "     Bachelor's degree in Engineering, Information Systems, Computer Scienc\n",
      "146 Responsibilities:\n",
      "\n",
      "    Incumbents work with large and complex data sets (both internal and external \n",
      "147 \n",
      "AGCO is looking to hire candidates for the position of Data Scientist l. This position is responsib\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "Waiting for 10 seconds API to reset\n",
      "148 Here is how, through this exciting role, YOU will contribute to BMC's and your own success: \n",
      "\n",
      "     B\n",
      "149 Key Responsibilities for Python Machine Learning Engineer\n",
      "\n",
      "    API Development & Maintenance\n",
      "    Des\n",
      "150 Key Accountabilities And Decision Ownership\n",
      "\n",
      "     Support build & deployment of analytical solutions\n",
      "151 Required Skills:\n",
      "\n",
      "Extensive experience with Kubernetes and cloud services (AWS, Azure, GCP, private \n",
      "152 Job Description\n",
      "\n",
      "Team Summary:\n",
      "\n",
      "Visa Consulting & Analytics (VCA) is Visa's consulting division, ser\n",
      "153 As a Data Scientist within IBM's Chief Analytics Office, you will support AI-driven projects across \n",
      "154 Accountabilities\n",
      "\n",
      "\n",
      "    Review and develop working practices to ensure that data science work is deli\n",
      "155 A Senior Machine Learning Engineer at Walmart is responsible for combining his engineering expertise\n",
      "156 Job Description:\n",
      "Your way to impact\n",
      "\n",
      "    You believe in data-driven decisions and use data to answer\n",
      "157 Job Description\n",
      "\n",
      "     Be a hands on problem solver with consultative approach, who can apply Machine\n",
      "158 What You’ll Bring\n",
      "\n",
      "Understand business and product needs and use classical ML methods or advanced AI\n",
      "159 What The Candidate Will Need / Bonus Points\n",
      "\n",
      "---- What the Candidate Will Do ----\n",
      "\n",
      "    Build scalabl\n",
      "160 Minimum Qualifications:\n",
      " \n",
      "\n",
      "    Bachelor’s/master’s degree in computer science, Engineering, Mathemat\n",
      "161 Your role and responsibilities\n",
      "\n",
      "In this role, you will have the opportunity to deliver and implement\n",
      "162 The Role\n",
      "\n",
      "To be successful in this role, the Data Scientist should have a deep knowledge of machine \n",
      "Waiting for 10 seconds API to reset\n",
      "163 We are looking for a AI/ML Engineer\n",
      "\n",
      "You’ll make a difference by:\n",
      "\n",
      "    We are seeking a highly skill\n",
      "164 \n",
      "Day to day responsibilities will include:\n",
      "\n",
      "    Conduct asset allocation and manager evaluation rese\n",
      "Waiting for 10 seconds API to reset\n",
      "165 ob Description\n",
      "\n",
      "We are seeking an experienced Data Scientist specializing in AI for Computer Vision \n",
      "166 You will \n",
      "\n",
      "    Develop scientific methods, processes, and systems to extract knowledge or insights t\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "all_my_stacks = []\n",
    "count = 0\n",
    "while count<len(all_descriptions):\n",
    "    raw_description = all_descriptions[count]\n",
    "    try:\n",
    "        job_description = \"\\n'''\" + raw_description+\"\\n'''\"\n",
    "        prompt = prompt_template+job_description\n",
    "        response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt)\n",
    "        job_json = response.text.strip(\"`\").replace(\"json\", \"\", 1).replace(\"\\n\",\"\")\n",
    "        job_json = json.loads(job_json)\n",
    "        mystack = TechStack.model_validate(job_json)\n",
    "        print(count,raw_description[0:100])\n",
    "        all_my_stacks.append(mystack)\n",
    "        count+=1 #only after successfull execution\n",
    "    except:\n",
    "        print(\"Waiting for 10 seconds API to reset\")\n",
    "        time.sleep(10)#Sleep 10 seconds. Google Gemini Flash has 5 Request Per Minute Rate Limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_my_stacks) #This indicates we can only run 26 prompts at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_my_stacks.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_my_stacks,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_my_stacks.pkl\",\"rb\") as f:\n",
    "    mynew_stacks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mynew_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TechStack(GPU_Frameworks=[], Programming_Languages=['Python', 'R'], Generative_AI_Frameworks=[], Databases=[], Orchestration_Deployment=[], APIs_Web_Frameworks=[], Big_Data_Technologies=[], Cloud_Platforms_Services=['AWS', 'Azure', 'Google Cloud Platform (GCP)'], Machine_Learning_Deep_Learning_Libraries=['Scikit-learn', 'PyTorch', 'TensorFlow'], Data_Visualization_Tools=[], CI_CD_MLOps=[], Model_Formats_Optimization=[], Qualifications=['BS', 'MS', 'B.E.', 'B.Tech', 'M.Tech'], Machine_Learning_AI_Techniques=['Natural Language Processing (NLP)', 'Computer Vision', 'Deep Learning', 'Generative AI'], Machine_Learning_AI_Models=['LLaMA'], Tasks_Responsibilities=['Develop & Deploy Machine Learning Models', 'Deploy Machine Learning Models', 'Maintain & Monitor Model Performance', 'Research & Develop Novel AI Techniques'], Soft_Skills=[], Miscellaneous=[])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynew_stacks[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the counts of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_keys= list(mynew_stacks[0].model_dump().keys())\n",
    "job_stack_count = {}\n",
    "for key in job_keys:\n",
    "    job_stack_count[key] = {} #Create an empty dict\n",
    "\n",
    "\n",
    "for stack in all_my_stacks:\n",
    "    dict_dump = stack.model_dump()\n",
    "    for key in job_keys[0:-2]: #Except the miscellaneous \n",
    "        mini_keys = dict_dump[key]\n",
    "        for mkey in mini_keys:\n",
    "            try:\n",
    "                job_stack_count[key][mkey] = job_stack_count[key][mkey]+1\n",
    "            except:\n",
    "                job_stack_count[key][mkey] = 0 #Assign if zero\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"job_stack_count.pkl\",\"wb\") as f:\n",
    "    pickle.dump(job_stack_count,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
